import torch.nn as nn
import torch
import torchvision.models as tm
import torch.nn.functional as F
import numpy as np
import random


class ROI_Pooling(nn.Module):
    '''
    å¤„ç†å•ä¸ªfeature mapçš„ roi å›¾åƒä¿¡æ¯
    '''

    def __init__(self):
        super().__init__()
        self.avgpool_patch = nn.AdaptiveAvgPool2d((1, 1))
        self.maxpool_patch = nn.AdaptiveMaxPool2d((1, 1))

    def forward(self, feature_map, cluster_center, spatial_ratio):
        feature_list = []
        cluster_center_mean = torch.mean(cluster_center, dim=0)
        cluster_center_normal = cluster_center_mean / spatial_ratio
        cluster_center_int = torch.floor(cluster_center_normal)
        cluster_center_float = cluster_center_normal - cluster_center_int
        cluster_center_offset = torch.round(cluster_center_float)
        cluster_center_offset = cluster_center_offset * 2 - 1  # è½¬åˆ°[-1,1]
        cluster_center_int = cluster_center_int + 1  # è½¬åˆ°[1,5]
        cluster_center_int = cluster_center_int + cluster_center_offset

        padding = (1, 1, 1, 1)
        # feature_map = F.pad(feature_map, padding, 'constant', 1)

        # for index in range(cluster_center_mean.shape[0]):
        #     coordinate_single = cluster_center_int[index]
        #     coordinate_single=coordinate_single.long()
        #     # x2 æ˜¯å› ä¸ºpython ç´¢å¼•çš„é—®é¢˜,ä»0å¼€å§‹,[0:1] åªç´¢å¼•ä¸€ä¸ª
        #
        #     patch = feature_map[:, :,
        #                         coordinate_single[0]:coordinate_single[0] + 2,
        #                         coordinate_single[1]:coordinate_single[1] + 2]
        #
        patch_avg = self.avgpool_patch(feature_map)
        patch_max = self.maxpool_patch(feature_map)
        patch_feature = patch_avg
        patch_flatten = torch.flatten(patch_feature, 1)
        feature_list.append(patch_flatten)

        return feature_list


class SpatialAttention(nn.Module):
    '''
    ç©ºé—´æ³¨æ„åŠ›æ¨¡å—
    '''

    def __init__(self, kernel_size=1):
        super(SpatialAttention, self).__init__()

        padding = 0

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()
        # self.avg = nn.AdaptiveAvgPool2d((3, 3))

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)


def modality_drop_v1(x_rgb, x_ir, x_depth, p, args):
    modality_combination = [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 1]]
    index_list = [x for x in range(7)]

    if p == [0, 0, 0]:
        # print("drop")
        p = []

        # for i in range(x_rgb.shape[0]):
        #     index = random.randint(0, 6)
        #     p.append(modality_combination[index])
        #     if 'model_arch_index' in args.writer_dicts.keys():
        #         args.writer_dicts['model_arch_index'].write(str(index) + " ")

        prob = np.array((1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7))
        prob = np.array((0, 0, 0, 0, 0, 0, 1))
        for i in range(x_rgb.shape[0]):
            index = np.random.choice(index_list, size=1, replace=True, p=prob)[0]
            p.append(modality_combination[index])
            # if 'model_arch_index' in args.writer_dicts.keys():
            #     args.writer_dicts['model_arch_index'].write(str(index) + " ")

        p = np.array(p)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

    else:
        p = p
        # print(p)
        p = [p * x_rgb.shape[0]]
        # print(p)
        p = np.array(p).reshape(x_rgb.shape[0], 3)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

        # print(p[:, 0], p[:, 1], p[:, 2])
    p = p.float().cuda()

    x_rgb = x_rgb * p[:, 0]
    x_ir = x_ir * p[:, 1]
    x_depth = x_depth * p[:, 2]
    p = p.squeeze()
    return x_rgb, x_ir, x_depth, p


import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
import seaborn as sns
import os
import time
from scipy.sparse import issparse
from sklearn.preprocessing import StandardScaler
import warnings

def universal_tsne_visualizer(input_features, labels=None, save_path='tsne_plot.png',
                              perplexity=30, learning_rate=200, n_iter=1000,
                              point_size=8, alpha=0.7, random_state=42,
                              apply_scaling=True, max_samples=5000):
    """
    é€šç”¨t-SNEå¯è§†åŒ–å·¥å…· - æ”¯æŒä»»æ„å½¢çŠ¶ç‰¹å¾è¾“å…¥

    å‚æ•°:
    input_features -- è¾“å…¥ç‰¹å¾ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰:
        - NumPyæ•°ç»„ï¼ˆ1D, 2D, 3Dï¼‰
        - PyTorch/TensorFlowå¼ é‡
        - ç¨€ç–çŸ©é˜µ
        - å­—å…¸/åˆ—è¡¨/DataFrame
        - ä»»ä½•å¯è¿­ä»£å¯¹è±¡
    labels -- å¯é€‰æ ‡ç­¾ï¼ˆé»˜è®¤ï¼šNoneï¼‰
    save_path -- å›¾ç‰‡ä¿å­˜è·¯å¾„ï¼ˆé»˜è®¤ï¼š'tsne_plot.png'ï¼‰
    perplexity -- t-SNEå›°æƒ‘åº¦ï¼ˆé»˜è®¤ï¼š30ï¼‰
    learning_rate -- å­¦ä¹ ç‡ï¼ˆé»˜è®¤ï¼š200ï¼‰
    n_iter -- è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š1000ï¼‰
    point_size -- ç‚¹å¤§å°ï¼ˆé»˜è®¤ï¼š8ï¼‰
    alpha -- é€æ˜åº¦ï¼ˆé»˜è®¤ï¼š0.7ï¼‰
    random_state -- éšæœºç§å­ï¼ˆé»˜è®¤ï¼š42ï¼‰
    apply_scaling -- æ˜¯å¦åº”ç”¨ç‰¹å¾ç¼©æ”¾ï¼ˆé»˜è®¤ï¼šTrueï¼‰
    max_samples -- æœ€å¤§æ ·æœ¬æ•°ï¼ˆè¶…è¿‡åˆ™é‡‡æ ·ï¼‰ï¼ˆé»˜è®¤ï¼š5000ï¼‰

    è¿”å›ï¼šé™ç»´åçš„äºŒç»´åæ ‡ (n_samples, 2)
    """
    start_time = time.time()
    warnings.filterwarnings("ignore", category=FutureWarning, message=".*'n_iter'.*")

    # 1. è½¬æ¢ä¸ºé€‚åˆt-SNEçš„æ ¼å¼
    #print("\nğŸ”§ é¢„å¤„ç†ç‰¹å¾æ•°æ®...")
    features, processed_labels = preprocess_input(input_features, labels, max_samples)

    # 2. ç‰¹å¾é¢„å¤„ç†
    #print(f"ğŸ“Š è¾“å…¥å½¢çŠ¶: {features.shape} | æ•°æ®ç±»å‹: {features.dtype}")

    # åº”ç”¨æ ‡å‡†åŒ–
    if apply_scaling:
        #print("ğŸ”¢ åº”ç”¨æ ‡å‡†åŒ–ï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰")
        scaler = StandardScaler()
        features = scaler.fit_transform(features)

    # 3. å¤„ç†å¤§æ•°æ®é›†
    if features.shape[0] > max_samples:
        print(f"ğŸ“ˆ æ•°æ®é›†è¾ƒå¤§ï¼ˆ{features.shape[0]}æ ·æœ¬ï¼‰ï¼Œé‡‡æ ·è‡³{max_samples}ä¸ªæ ·æœ¬")
        indices = np.random.choice(features.shape[0], max_samples, replace=False)
        features = features[indices]
        if processed_labels is not None:
            processed_labels = processed_labels[indices]

    # 4. æ‰§è¡Œt-SNE
    # print("\nğŸŒ€ æ‰§è¡Œt-SNEé™ç»´...")
    # print(f"æ ·æœ¬æ•°: {features.shape[0]} | ç‰¹å¾æ•°: {features.shape[1]}")
    # print(f"è¶…å‚æ•°: å›°æƒ‘åº¦={perplexity}, å­¦ä¹ ç‡={learning_rate}, è¿­ä»£æ¬¡æ•°={n_iter}")

    tsne = TSNE(n_components=2,
                perplexity=perplexity,
                learning_rate=learning_rate,
                max_iter=n_iter,
                random_state=random_state,
                n_jobs=-1)  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ

    embedding = tsne.fit_transform(features)

    elapsed = time.time() - start_time
    #print(f"âœ… t-SNEå®Œæˆ! è€—æ—¶: {elapsed:.2f}ç§’")

    # 5. å¯è§†åŒ–
    #print("\nğŸ¨ åˆ›å»ºå¯è§†åŒ–...")
    plt.figure(figsize=(10, 8))

    # æœ‰æ ‡ç­¾æ—¶ä½¿ç”¨åˆ†ç±»ç€è‰²
    if processed_labels is not None:
        plot_with_labels(embedding, processed_labels, point_size, alpha)
    # æ— æ ‡ç­¾æ—¶ä½¿ç”¨å•ä¸€é¢œè‰²
    else:
        plt.scatter(embedding[:, 0], embedding[:, 1],
                    s=point_size, alpha=alpha,
                    color='royalblue')

    # æ·»åŠ æ ‡é¢˜å’Œæ ‡ç­¾
    # ä¿®æ”¹æ ‡é¢˜å’Œåæ ‡è½´æ ‡ç­¾ä¸ºè‹±æ–‡
    plt.title(f't-SNE Visualization (n={embedding.shape[0]}, dim={features.shape[1]})', fontsize=14)
    plt.xlabel('t-SNE Dimension 1', fontsize=12)
    plt.ylabel('t-SNE Dimension 2', fontsize=12)
    plt.grid(alpha=0.2)

    # ä¿å­˜å›¾ç‰‡
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    # print(f"\nğŸ’¾ t-SNEå›¾å·²ä¿å­˜è‡³: {os.path.abspath(save_path)}")
    plt.close()

    return embedding


def preprocess_input(features, labels, max_samples):
    """å°†å„ç§æ ¼å¼çš„è¾“å…¥è½¬æ¢ä¸ºæ ‡å‡†çš„2Dç‰¹å¾çŸ©é˜µ"""
    # å¤„ç†æ ‡ç­¾
    processed_labels = None
    if labels is not None:
        processed_labels = convert_to_numpy(labels).flatten()

    # å¤„ç†å„ç§ç‰¹å¾ç±»å‹
    # 1. å·²ç»æ˜¯2D numpyæ•°ç»„
    if isinstance(features, np.ndarray) and features.ndim == 2:
        return features, processed_labels

    # 2. å°†å…¶ä»–æ ¼å¼è½¬æ¢ä¸ºnumpy
    processed_features = convert_to_numpy(features)

    # 3. å¤„ç†1Dæ•°ç»„ï¼ˆå•ä¸ªæ ·æœ¬ï¼‰
    if processed_features.ndim == 1:
        processed_features = processed_features.reshape(1, -1)

    # 4. å¤„ç†3Dæˆ–æ›´é«˜ç»´æ•°ç»„ï¼ˆå¦‚BCHWå›¾åƒç‰¹å¾ï¼‰
    if processed_features.ndim > 2:
        #print(f"âš ï¸ æ£€æµ‹åˆ°{processed_features.ndim}ç»´è¾“å…¥ï¼Œå±•å¹³ä¸º2DçŸ©é˜µ")
        original_shape = processed_features.shape
        processed_features = processed_features.reshape(original_shape[0], -1)
        #print(f"  åŸå§‹å½¢çŠ¶: {original_shape} -> æ–°å½¢çŠ¶: {processed_features.shape}")

    # 5. å¤„ç†ç¨€ç–çŸ©é˜µ
    if issparse(processed_features):
        print(f"âš ï¸ æ£€æµ‹åˆ°ç¨€ç–çŸ©é˜µï¼ˆ{type(processed_features)}ï¼‰ï¼Œè½¬æ¢ä¸ºå¯†é›†æ ¼å¼")
        processed_features = processed_features.toarray()

    # 6. ç¡®ä¿è‡³å°‘2ç»´
    if processed_features.ndim != 2:
        raise ValueError(f"æ— æ³•å°†è¾“å…¥è½¬æ¢ä¸º2DçŸ©é˜µã€‚æœ€ç»ˆç»´åº¦: {processed_features.ndim}")

    return processed_features, processed_labels


def convert_to_numpy(data):
    """å°†å„ç§æ•°æ®ç±»å‹è½¬æ¢ä¸ºNumPyæ•°ç»„"""
    # 1. å·²ç»æ˜¯numpyæ•°ç»„
    if isinstance(data, np.ndarray):
        return data

    # 2. PyTorchå¼ é‡
    if hasattr(data, 'detach') and hasattr(data, 'numpy'):
        return data.detach().cpu().numpy()

    # 3. TensorFlowå¼ é‡
    if hasattr(data, 'numpy'):
        return data.numpy()

    # 4. pandas DataFrame/Series
    if hasattr(data, 'values'):
        return data.values

    # 5. ç¨€ç–çŸ©é˜µ
    if issparse(data):
        return data

    # 6. å­—å…¸ç±»å‹ï¼ˆé”®ä½œä¸ºç‰¹å¾ï¼‰
    if isinstance(data, dict):
        return np.array(list(data.values()))

    # 7. åˆ—è¡¨æˆ–å…ƒç»„
    if isinstance(data, (list, tuple)):
        return np.array(data)

    # 8. å•ä¸ªå€¼ï¼ˆæ ‡é‡ï¼‰
    try:
        scalar = float(data)
        return np.array([scalar])
    except:
        pass

    # 9. å…¶ä»–å¯è¿­ä»£å¯¹è±¡
    try:
        return np.array([x for x in data])
    except:
        pass

    raise TypeError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(data)}")


def plot_with_labels(embedding, labels, point_size, alpha):
    """å¸¦æ ‡ç­¾çš„t-SNEå¯è§†åŒ–"""
    unique_labels = np.unique(labels)
    num_classes = len(unique_labels)

    # è‡ªåŠ¨é€‰æ‹©ç»˜å›¾ç­–ç•¥
    if num_classes <= 12:
        # ç±»åˆ«å°‘æ—¶ä½¿ç”¨ä¸åŒé¢œè‰²
        plot_colored(embedding, labels, point_size, alpha)
    elif num_classes <= 30:
        # ä¸­ç­‰ç±»åˆ«ä½¿ç”¨é¢œè‰²+å½¢çŠ¶
        plot_colored_with_shapes(embedding, labels, point_size, alpha)
    else:
        # å¤§é‡ç±»åˆ«ä½¿ç”¨è¿ç»­è‰²è°±
        plot_continuous(embedding, labels, point_size, alpha)


def plot_colored(embedding, labels, point_size, alpha):
    """ç±»åˆ«å°‘äº12ä¸ªæ—¶çš„ç€è‰²æ–¹æ¡ˆ"""
    unique_labels = np.unique(labels)
    palette = sns.color_palette("tab10", len(unique_labels))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'X']

    for i, label in enumerate(unique_labels):
        mask = labels == label
        # ä¸ºä¸åŒç±»åˆ«ä½¿ç”¨ä¸åŒæ ‡è®°
        marker = markers[i % len(markers)] if len(unique_labels) > 6 else 'o'
        plt.scatter(embedding[mask, 0], embedding[mask, 1],
                    s=point_size, alpha=alpha,
                    color=palette[i],
                    marker=marker,
                    label=str(label))

    plt.legend(title='Labels', bbox_to_anchor=(1.05, 1), loc='upper left')


def plot_colored_with_shapes(embedding, labels, point_size, alpha):
    """ä¸­ç­‰ç±»åˆ«æ•°çš„ç€è‰²æ–¹æ¡ˆï¼ˆé¢œè‰²+å½¢çŠ¶ï¼‰"""
    unique_labels = np.unique(labels)
    palette = sns.color_palette("husl", min(len(unique_labels), 12))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'X', 'h', '+']

    for i, label in enumerate(unique_labels):
        mask = labels == label
        color_idx = i % len(palette)
        marker_idx = (i // len(palette)) % len(markers)
        plt.scatter(embedding[mask, 0], embedding[mask, 1],
                    s=point_size, alpha=alpha,
                    color=palette[color_idx],
                    marker=markers[marker_idx],
                    label=str(label))

    plt.legend(title='Labels', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)


def plot_continuous(embedding, labels, point_size, alpha):
    """å¤§é‡ç±»åˆ«æ—¶çš„è¿ç»­ç€è‰²æ–¹æ¡ˆ"""
    print(f"âš ï¸ æ£€æµ‹åˆ°å¤§é‡ç±»åˆ«ï¼ˆ{len(np.unique(labels))}ï¼‰ï¼Œä½¿ç”¨è¿ç»­è‰²è°±")
    plt.scatter(embedding[:, 0], embedding[:, 1],
                s=point_size, alpha=alpha,
                c=labels, cmap='viridis')
    plt.colorbar(label='Label Values')

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from tqdm import tqdm
import torch
import random


def extract_features_with_sampling(model, loader, max_samples=2000, verbose=False):
    """
    ä»æµ‹è¯•é›†ä¸­æå–ç‰¹å¾å¹¶è¿›è¡Œéšæœºé‡‡æ ·

    å‚æ•°:
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    loader: æ•°æ®åŠ è½½å™¨
    max_samples: æœ€å¤§é‡‡æ ·æ ·æœ¬æ•°
    verbose: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡

    è¿”å›:
    åŒ…å«ç‰¹å¾å¼ é‡å’Œæ ‡ç­¾çš„å­—å…¸
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    model.eval()

    # åˆå§‹åŒ–ç‰¹å¾å­˜å‚¨
    all_features = {
        'layer4': [],
        'mul': [],
        'std': [],
        'fe': [],
        'labels': []
    }

    # å­˜å‚¨æ‰€æœ‰æ‰¹æ¬¡çš„ç‰¹å¾
    full_features = {
        'layer4': [],
        'mul': [],
        'std': [],
        'fe': [],
        'labels': []
    }

    with torch.no_grad():
        for batch_sample in tqdm(iter(loader), desc="Extracting features",
                                 total=len(loader), disable=not verbose):
            # æå–è¾“å…¥æ•°æ®å’Œæ ‡ç­¾
            img_rgb = batch_sample['image_x'].to(device)
            img_ir = batch_sample['image_ir'].to(device)
            img_depth = batch_sample['image_depth'].to(device)
            labels = batch_sample['binary_label'].to(device)

            # å‰å‘ä¼ æ’­è·å–ç‰¹å¾
            output, p, mul, std, x_m, layer4,s = model(img_rgb, img_ir, img_depth)

            # è®¡ç®—feç‰¹å¾
            fe = mul + std

            # æ”¶é›†ç‰¹å¾æ•°æ® - ä¿æŒåŸå§‹ç»´åº¦
            full_features['layer4'].append(layer4.cpu())
            full_features['mul'].append(mul.cpu())
            full_features['std'].append(std.cpu())
            full_features['fe'].append(fe.cpu())
            full_features['labels'].append(labels.cpu())

    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„æ•°æ®
    for key in full_features:
        if full_features[key]:
            full_features[key] = torch.cat(full_features[key], dim=0)

    # é‡‡æ ·é€»è¾‘
    total_samples = full_features['labels'].shape[0]
    if max_samples < total_samples:
        # ç¡®ä¿æ¯ä¸ªç±»åˆ«æŒ‰æ¯”ä¾‹é‡‡æ ·
        class_0_idx = torch.where(full_features['labels'] == 0)[0]
        class_1_idx = torch.where(full_features['labels'] == 1)[0]

        # æŒ‰ç±»åˆ«æ¯”ä¾‹è®¡ç®—é‡‡æ ·æ•°é‡
        class_0_samples = int(max_samples * len(class_0_idx) / total_samples)
        class_1_samples = int(max_samples * len(class_1_idx) / total_samples)
        total_samples = class_0_samples + class_1_samples

        # éšæœºé‡‡æ ·
        sampled_class_0 = random.sample(class_0_idx.tolist(), min(class_0_samples, len(class_0_idx)))
        sampled_class_1 = random.sample(class_1_idx.tolist(), min(class_1_samples, len(class_1_idx)))
        sampled_indices = torch.tensor(sampled_class_0 + sampled_class_1)

        # ä½¿ç”¨é‡‡æ ·ç´¢å¼•æå–ç‰¹å¾
        for key in all_features:
            all_features[key] = full_features[key][sampled_indices]
    else:
        # å¦‚æœæ²¡æœ‰è¶…è¿‡æœ€å¤§æ ·æœ¬æ•°ï¼Œåˆ™ä½¿ç”¨å…¨éƒ¨æ•°æ®
        all_features = full_features

    print(f"Selected {len(all_features['labels'])} samples for t-SNE visualization.")
    return all_features


def visualize_tsne_for_feature(feature, labels, save_path, feature_name, perplexity=20):
    """
    ç»˜åˆ¶å•ä¸ªç‰¹å¾çš„t-SNEå›¾å¹¶ä¿å­˜

    å‚æ•°:
    feature: ç‰¹å¾å¼ é‡ (B, C, H, W)
    labels: æ ‡ç­¾å¼ é‡ (B,)
    save_path: å›¾åƒä¿å­˜å®Œæ•´è·¯å¾„ï¼ˆåŒ…å«æ–‡ä»¶åï¼‰
    feature_name: ç‰¹å¾åç§°ï¼ˆç”¨äºæ ‡é¢˜ï¼‰
    perplexity: t-SNEå¤æ‚åº¦å‚æ•°
    """
    # å‡†å¤‡ç‰¹å¾æ•°æ®
    feature = feature.view(feature.size(0), -1).numpy()  # å±•å¹³ä¸º(B, C*H*W)
    labels = labels.numpy()

    # PCAé¢„å¤„ç†ï¼ˆå½“ç»´åº¦>100æ—¶ï¼‰
    if feature.shape[1] > 100:
        pca = PCA(n_components=min(50, feature.shape[1]))
        feature = pca.fit_transform(feature)

    # ç‰¹å¾æ ‡å‡†åŒ–
    scaler = StandardScaler()
    feature_scaled = scaler.fit_transform(feature)

    # t-SNEé™ç»´
    tsne = TSNE(n_components=2, perplexity=perplexity,
                random_state=42, n_iter=1000, learning_rate=200)
    embedding = tsne.fit_transform(feature_scaled)

    # åˆ›å»ºå›¾å½¢
    plt.figure(figsize=(12, 10))

    # åˆ†ç¦»ä¸åŒç±»åˆ«
    class_0_mask = (labels == 0)
    class_1_mask = (labels == 1)

    # ç»˜åˆ¶æ•£ç‚¹å›¾
    plt.scatter(embedding[class_0_mask, 0], embedding[class_0_mask, 1],
                color='#1f77b4', alpha=0.7, s=40, label='Class 0 (Real)',
                edgecolors='w', linewidths=0.5)

    plt.scatter(embedding[class_1_mask, 0], embedding[class_1_mask, 1],
                color='#d62728', alpha=0.7, s=40, label='Class 1 (Fake)',
                edgecolors='w', linewidths=0.5)

    # æ·»åŠ æ ‡é¢˜å’Œå›¾ä¾‹
    title_name = {
        'layer4': 'CNN Layer 4 Features',
        'mul': 'Multiplication Features',
        'std': 'Standard Deviation Features',
        'fe': 'Combined (mul+std) Features'
    }.get(feature_name, feature_name)

    plt.title(f't-SNE Visualization of {title_name}', fontsize=16, pad=15)
    plt.legend(loc='best', fontsize=12, framealpha=0.9)

    # ç§»é™¤åæ ‡è½´å’Œç½‘æ ¼çº¿
    plt.axis('off')

    # æ·»åŠ æ–‡æœ¬æ ‡ç­¾
    plt.text(0.99, 0.01, f'n={len(labels)}, perplexity={perplexity}',
             transform=plt.gca().transAxes, fontsize=10,
             horizontalalignment='right', verticalalignment='bottom')

    # ä¿å­˜å›¾åƒ
    plt.savefig(save_path, dpi=300, bbox_inches='tight', pad_inches=0.2)
    plt.close()
    print(f"Saved t-SNE plot to: {save_path}")


def visualize_all_features_tsne(model, loader, save_path_template, max_samples=2000, epoch=0, batch_num=0,
                                verbose=False):
    """
    æå–ç‰¹å¾å¹¶ç»˜åˆ¶æ‰€æœ‰ç‰¹å¾çš„t-SNEå›¾

    å‚æ•°:
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    loader: æ•°æ®åŠ è½½å™¨
    save_path_template: å›¾åƒä¿å­˜è·¯å¾„æ¨¡æ¿ï¼ŒåŒ…å«{feature}å ä½ç¬¦
    max_samples: æœ€å¤§é‡‡æ ·æ ·æœ¬æ•°
    epoch: å½“å‰epochï¼ˆç”¨äºæ–‡ä»¶åï¼‰
    batch_num: å½“å‰batchç¼–å·ï¼ˆç”¨äºæ–‡ä»¶åï¼‰
    verbose: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
    """
    # æå–ç‰¹å¾å¹¶è¿›è¡Œé‡‡æ ·
    features_dict = extract_features_with_sampling(model, loader, max_samples, verbose)

    # ä¸ºæ¯ä¸ªç‰¹å¾ç»˜åˆ¶t-SNEå›¾
    feature_names = ['layer4', 'mul', 'std', 'fe']

    for feat_name in feature_names:
        if feat_name in features_dict and features_dict[feat_name].numel() > 0:
            # æ„å»ºç‰¹å®šç‰¹å¾çš„ä¿å­˜è·¯å¾„
            save_path = save_path_template.format(
                epoch=epoch,
                batch=batch_num,
                feature=feat_name
            )

            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            os.makedirs(os.path.dirname(save_path), exist_ok=True)

            # å¯è§†åŒ–å•ä¸ªç‰¹å¾
            visualize_tsne_for_feature(
                feature=features_dict[feat_name],
                labels=features_dict['labels'],
                save_path=save_path,
                feature_name=feat_name
            )
        else:
            print(f"Warning: Feature '{feat_name}' not found or empty. Skipping.")

    return features_dict

def modality_drop(x_rgb, x_ir, x_depth, p, args):
    # print(p)
    modality_combination = [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 1]]
    # p=[1,1,1]
    index_list = [x for x in range(7)]

    if p == [0, 0, 0]:
        # print("drop")
        p = []

        # for i in range(x_rgb.shape[0]):
        #     index = random.randint(0, 6)
        #     p.append(modality_combination[index])
        #     if 'model_arch_index' in args.writer_dicts.keys():
        #         args.writer_dicts['model_arch_index'].write(str(index) + " ")
        prob = np.array(( 1 / 7, 1 / 7,1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7))
        for i in range(x_rgb.shape[0]):
            index = np.random.choice(index_list, size=1, replace=True, p=prob)[0]
            p.append(modality_combination[index])
            # if 'model_arch_index' in args.writer_dicts.keys():
            #     args.writer_dicts['model_arch_index'].write(str(index) + " ")

        p = np.array(p)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

    else:
        p = p
        # print(p)
        p = [p * x_rgb.shape[0]]
        # print(p)
        p = np.array(p).reshape(x_rgb.shape[0], 3)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

        # print(p[:, 0], p[:, 1], p[:, 2])
    p = p.float().cuda()

    x_rgb = x_rgb * p[:, 0]
    x_ir = x_ir * p[:, 1]
    x_depth = x_depth * p[:, 2]
    p = p.squeeze()

    return x_rgb, x_ir, x_depth, p


def modality_drop_p(x_rgb, x_ir, x_depth, p, args):
    """
    å¯¹RGBã€çº¢å¤–(IR)å’Œæ·±åº¦(Depth)æ¨¡æ€åº”ç”¨æ¨¡æ€ä¸¢å¼ƒ(Modality Dropout)[2](@ref)ã€‚
    è¾“å…¥å¼ é‡å½¢çŠ¶åº”ä¸º (B, C, H, W)ï¼Œä¾‹å¦‚ (B, 3, 112, 112)ã€‚

    å‚æ•°:
        x_rgb: RGBæ¨¡æ€è¾“å…¥å¼ é‡
        x_ir: çº¢å¤–æ¨¡æ€è¾“å…¥å¼ é‡
        x_depth: æ·±åº¦æ¨¡æ€è¾“å…¥å¼ é‡
        p: é¢„å®šä¹‰çš„æ¨¡æ€ä¿ç•™æ¦‚ç‡åˆ—è¡¨ï¼Œå¦‚ [1,1,1] è¡¨ç¤ºå…¨éƒ¨ä¿ç•™ã€‚
           å¦‚æœä¸º [0,0,0]ï¼Œåˆ™ä»7ç§å›ºå®šç»„åˆä¸­éšæœºé€‰æ‹©ã€‚
        args: åŒ…å«å…¶ä»–å‚æ•°çš„å‘½åå…ƒç»„æˆ–å­—å…¸ï¼ˆç”¨äºæ—¥å¿—è®°å½•ç­‰ï¼‰

    è¿”å›:
        x_rgb: åº”ç”¨æ¨¡æ€ä¸¢å¼ƒåçš„RGBå¼ é‡
        x_ir: åº”ç”¨æ¨¡æ€ä¸¢å¼ƒåçš„çº¢å¤–å¼ é‡
        x_depth: åº”ç”¨æ¨¡æ€ä¸¢å¼ƒåçš„æ·±åº¦å¼ é‡
        p: å®é™…ä½¿ç”¨çš„æ©ç å¼ é‡ï¼ˆå½¢çŠ¶ä¸º(B, 3)ï¼‰ï¼Œä¾¿äºåç»­åˆ†æ
    """
    # 7ç§å¯èƒ½çš„æ¨¡æ€ç»„åˆ[2](@ref): [RGB, IR, Depth]
    modality_combination = [[1, 0, 0], [0, 1, 0], [0, 0, 1],
                            [1, 1, 0], [1, 0, 1], [0, 1, 1],
                            [1, 1, 1]]
    index_list = [x for x in range(7)]  # ç»„åˆç´¢å¼•åˆ—è¡¨

    if p == [0, 0, 0]:
        # éšæœºé€‰æ‹©æ¨¡æ€ç»„åˆ[2](@ref)
        p = []
        # ä¸ºæ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬éšæœºé€‰æ‹©ä¸€ç§æ¨¡æ€ç»„åˆ
        prob = np.array([1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7])  # å‡åŒ€æ¦‚ç‡
        for i in range(x_rgb.shape[0]):
            index = np.random.choice(index_list, size=1, replace=True, p=prob)[0]
            p.append(modality_combination[index])
            # å¦‚æœéœ€è¦è®°å½•ç´¢å¼•ï¼ˆä¾‹å¦‚ç”¨äºæ—¥å¿—è®°å½•æˆ–åˆ†æï¼‰ï¼Œå¯ä»¥åœ¨æ­¤å¤„ä½¿ç”¨argsä¸­çš„å†™å…¥å™¨
            # if 'model_arch_index' in args.writer_dicts.keys():
            #     args.writer_dicts['model_arch_index'].write(str(index) + " ")

        p = np.array(p)
        p = torch.from_numpy(p)

    else:
        # ä½¿ç”¨ç»™å®šçš„æ¦‚ç‡pï¼Œå¹¶æ‰©å±•åˆ°æ•´ä¸ªæ‰¹æ¬¡
        p = p
        p = [p] * x_rgb.shape[0]  # ä¸ºæ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬ä½¿ç”¨ç›¸åŒçš„æ¦‚ç‡
        p = np.array(p).reshape(x_rgb.shape[0], 3)
        p = torch.from_numpy(p)

    # å°†pè½¬æ¢ä¸ºFloatTensorå¹¶ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœè¾“å…¥å¼ é‡åœ¨GPUä¸Šï¼‰
    p = p.float().to(x_rgb.device)

    # è°ƒæ•´æ©ç ç»´åº¦ä»¥åŒ¹é…è¾“å…¥å¼ é‡ (B, 3, 112, 112)
    # ä» (B, 3) æ‰©å±•ä¸º (B, 3, 1, 1)ï¼Œä»¥ä¾¿é€šè¿‡å¹¿æ’­ä¸ (B, 3, 112, 112) ç›¸ä¹˜
    p_expanded = p.unsqueeze(-1).unsqueeze(-1)  # ç°åœ¨å½¢çŠ¶æ˜¯ (B, 3, 1, 1)

    # å¯¹æ¯ä¸ªæ¨¡æ€åº”ç”¨æ©ç 
    x_rgb = x_rgb * p_expanded[:, 0]  # ä½¿ç”¨RGBå¯¹åº”çš„æ©ç ï¼ˆç¬¬0åˆ—ï¼‰
    x_ir = x_ir * p_expanded[:, 1]  # ä½¿ç”¨IRå¯¹åº”çš„æ©ç ï¼ˆç¬¬1åˆ—ï¼‰
    x_depth = x_depth * p_expanded[:, 2]  # ä½¿ç”¨Depthå¯¹åº”çš„æ©ç ï¼ˆç¬¬2åˆ—ï¼‰

    # è¿”å›å¤„ç†åçš„å¼ é‡å’Œæ©ç ï¼ˆæ©ç pçš„å½¢çŠ¶ä¸º(B, 3)ï¼‰
    return x_rgb, x_ir, x_depth, p

def modality_drop_v(x_rgb, x_ir, x_depth, p, args):
    modality_combination = [[1, 0, 0], [0, 1, 0], [0, 0, 1],
                            [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 1]]

    index_list = [x for x in range(7)]

    # åˆ›å»ºè¾“å…¥æ•°æ®çš„å‰¯æœ¬ï¼Œä»¥ä¾¿åˆ†åˆ«å¤„ç†åŸå§‹ç¼ºå¤±å’Œå¯¹ç«‹ç¼ºå¤±
    x_rgb_orig = x_rgb.clone()
    x_ir_orig = x_ir.clone()
    x_depth_orig = x_depth.clone()

    if p == [0, 0, 0]:
        # éšæœºç”Ÿæˆç¼ºå¤±æ¨¡å¼
        prob = np.array((1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7))
        p_list = []
        for i in range(x_rgb.shape[0]):
            index = np.random.choice(index_list, size=1, replace=True, p=prob)[0]
            p_list.append(modality_combination[index])
            # if 'model_arch_index' in args.writer_dicts.keys():
            #     args.writer_dicts['model_arch_index'].write(str(index) + " ")

        p = np.array(p_list)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

    else:
        # é‡ç”¨ç»™å®šçš„ç¼ºå¤±æ¨¡å¼
        p = [p] * x_rgb.shape[0]  # å¤åˆ¶åˆ°batchä¸­æ¯ä¸ªæ ·æœ¬
        p = np.array(p).reshape(x_rgb.shape[0], 3)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

    p = p.float().cuda()

    # åº”ç”¨åŸå§‹ç¼ºå¤±æ¨¡å¼åˆ°è¾“å…¥æ•°æ®
    x_rgb_original_drop = x_rgb_orig * p[:, 0]
    x_ir_original_drop = x_ir_orig * p[:, 1]
    x_depth_original_drop = x_depth_orig * p[:, 2]

    # å‡†å¤‡è¿”å›çš„p (ç§»é™¤å¤šä½™çš„ç»´åº¦)
    p_return = p.squeeze()

    # è®¡ç®—å¯¹ç«‹ç¼ºå¤±æ¨¡å¼q (0->1, 1->0)
    q = 1 - p_return
    # ç‰¹æ®Šæƒ…å†µå¤„ç†ï¼šå½“åŸå§‹æ¨¡å¼æ˜¯[1,1,1]æ—¶ï¼Œå¯¹ç«‹æ¨¡å¼ä¹Ÿè®¾ä¸º[1,1,1]
    all_ones = torch.all(p_return == 1, dim=1)
    q[all_ones] = p_return[all_ones]

    # æ‰©å±•qçš„ç»´åº¦ä»¥åŒ¹é…è¾“å…¥æ•°æ®çš„ç»´åº¦
    q_expanded = q.unsqueeze(2).unsqueeze(3).unsqueeze(4)

    # åº”ç”¨å¯¹ç«‹ç¼ºå¤±æ¨¡å¼åˆ°è¾“å…¥æ•°æ®
    x_rgb_opposite_drop = x_rgb_orig * q_expanded[:, 0]
    x_ir_opposite_drop = x_ir_orig * q_expanded[:, 1]
    x_depth_opposite_drop = x_depth_orig * q_expanded[:, 2]

    # è¿”å›ä¸¤ç»„æ•°æ®ï¼šåŸå§‹ç¼ºå¤±å¤„ç†åçš„æ•°æ®å’Œå¯¹ç«‹ç¼ºå¤±å¤„ç†åçš„æ•°æ®
    return  x_rgb_original_drop, x_ir_original_drop, x_depth_original_drop,x_rgb_opposite_drop, x_ir_opposite_drop, x_depth_opposite_drop,  p_return, q


def modality_drop1(x_rgb, x_ir, x_depth, p, args):
    modality_combination = [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 1]]
    index_list = [x for x in range(7)]

    if p == [0, 0, 0]:
        # print("drop")
        p = []

        # for i in range(x_rgb.shape[0]):
        #     index = random.randint(0, 6)
        #     p.append(modality_combination[index])
        #     if 'model_arch_index' in args.writer_dicts.keys():
        #         args.writer_dicts['model_arch_index'].write(str(index) + " ")
        prob = np.array(( 11/42, 2/21,11/42, 2/21, 2/21, 2/21, 2/21))
        for i in range(x_rgb.shape[0]):
            index = np.random.choice(index_list, size=1, replace=True, p=prob)[0]
            p.append(modality_combination[index])
            # if 'model_arch_index' in args.writer_dicts.keys():
            #     args.writer_dicts['model_arch_index'].write(str(index) + " ")

        p = np.array(p)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

    else:
        p = p
        # print(p)
        p = [p * x_rgb.shape[0]]
        # print(p)
        p = np.array(p).reshape(x_rgb.shape[0], 3)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

        # print(p[:, 0], p[:, 1], p[:, 2])
    p = p.float().cuda()

    x_rgb = x_rgb * p[:, 0]
    x_ir = x_ir * p[:, 1]
    x_depth = x_depth * p[:, 2]

    return x_rgb, x_ir, x_depth, p
def unbalance_modality_drop(x_rgb, x_ir, x_depth, p, args):
    modality_combination = [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 1]]
    index_list = [x for x in range(7)]
    prob = np.array((1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7, 1 / 7))
    # print(args.epoch)
    mode_num = 7
    hard_mode_index = [0, 2, 4]
    mode_average = x_rgb.shape[0] // mode_num
    batch_left = x_rgb.shape[0] % mode_num
    mode_left = 2
    if p == [0, 0, 0]:
        p = []
        # prob = np.array([3 / 12, 1 / 12, 3 / 12, 1 / 12, 2 / 12, 1 / 12, 1 / 12])
        # for i in range(x_rgb.shape[0]):
        #     index = np.random.choice(index_list, size=1, replace=True, p=prob)[0]
        #     p.append(modality_combination[index])
        #     # if 'model_arch_index' in args.writer_dicts.keys():
        #     #     args.writer_dicts['model_arch_index'].write(str(index) + " ")
        #
        # p = np.array(p)
        # p = torch.from_numpy(p)
        # p = torch.unsqueeze(p, 2)
        # p = torch.unsqueeze(p, 3)
        # p = torch.unsqueeze(p, 4)

        if args.epoch < 15:
            for i in range(mode_num):
                p = p + modality_combination[i] * mode_average
            for i in range(batch_left):
                p = p + modality_combination[i]
        else:
            increase_num =  args.epoch - 15
            if increase_num > 7:
                increase_num = 7

            # print(increase_num)
            for i in hard_mode_index:
                p = p + modality_combination[i] * (mode_average + increase_num)

            decrease_num = args.epoch - 15
            if decrease_num > 7:
                decrease_num = 7

            # print(decrease_num)
            for i in [3,5,6]:
                p = p + modality_combination[i] * (mode_average - decrease_num)
            p=p + modality_combination[1] * mode_average
            for i in range(batch_left):
                p = p + modality_combination[i]

        # p = p + modality_combination[2] * 17
        # for i in [0, 4]:
        #     p = p + modality_combination[i] * 11
        # for i in [1, 3, 5]:
        #     p = p + modality_combination[i] * 7
        # p = p + modality_combination[6] * 4
        p = np.array(p)
        p = p.reshape((64, 3))
        np.random.shuffle(p)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)



    else:
        p = p
        p = [p * x_rgb.shape[0]]
        p = np.array(p).reshape(x_rgb.shape[0], 3)
        p = torch.from_numpy(p)
        p = torch.unsqueeze(p, 2)
        p = torch.unsqueeze(p, 3)
        p = torch.unsqueeze(p, 4)

        # print(p[:, 0], p[:, 1], p[:, 2])
    p = p.float().cuda()

    x_rgb = x_rgb * p[:, 0]
    x_ir = x_ir * p[:, 1]
    x_depth = x_depth * p[:, 2]

    return x_rgb, x_ir, x_depth, p
